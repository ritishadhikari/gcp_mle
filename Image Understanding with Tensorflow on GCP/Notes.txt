Introduction

Linear and DNN models
The ideal decision boundary of cat vs non cat is defined by the relationship between pixels. 

Convolutional Neural Networks

The Larger the size of the kernel, the smaller the output of the convolution layers

Add smaller filters while adding more convolutional layers. Strides of a kernel is usually set to 
smaller than the size of the kernels. 

Dealing with Data Scarcity

For a Linear Model, the number of parameters is: Height * Width * NClasses + NCLASSES

Common Image Augmentation Techniques:
    - Blur
    - Resize
    - Sharpen
    - Crop
    - Flip
    - Rotate
    - Change Hue, Brightness or Contrast

For Transfer Learning:
    - Cut the layers at the output. 
    - If dataset is small, then do not update the weight of the network, else update the weights
    of the original network. 

Going Deeper Faster:

Address Internal Covariate Shift using Batch Normalization. 
Add shortcut connections to increase network depth
Take advantage of Tensor Processing Units
Automate network architecture.

Deeper networks takes a lot of time to train and they are very sensitive to hyperparameters.

Batch Normalization scales the weights between layers albeit by keeping a high learning rate. 

TPU configs:
	- 4 chips/TPU, 2 Cores/chip, 8 GB memory/core, 64 TPUs/pod.
	- It provides high-speed interconnect
	- Offers very large matrix multiplication hardware. 
	- TPUs are mainly intended for Batch Predictions. 
	- There are specialized instruction set
	- TPU uses bfloat or dloat32 floating point representation.

Pre-built models:

Auto ML and Vision API

Auto ML is for everyone while Cloud Vision API or Cloud Video Intelligence API requires Data Analysts, 
Data Scientists and Data Engineers

